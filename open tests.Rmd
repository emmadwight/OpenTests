---
title: 'Open Tests: Harvard Measurement Lab'
author: "Emma Dwight"
date: "7/17/2020"
output:
  pdf_document: default
  md_document:
    variant: markdown_github
  word_document: default
  html_document:
    df_print: paged
---
In this tutorial we show how schools, districts, and states can create and score a test comprised of publicly available questions from state websites. As our example, we use MCAS 4th grade ELA and released questions from 2018.

# Ingredients:
1) Released test questions (items) to create the test, like these:

![Source: https://mcas.digitalitemlibrary.com/home?subject=ELA&grades=Grade%204&view=ALL](images/1_released_items.png)
https://mcas.digitalitemlibrary.com/home?subject=ELA&grades=Grade%204&view=ALL

2) Released item IRT parameter estimates, like table M5 here:

![Source: http://www.mcasservicecenter.com/documents/MA/Technical%20Report/2018/NextGen/Appendix%20M%20-%20Plots%20and%20IRT%20Parameters.pdf](images/2_item_parameters.png)

http://www.mcasservicecenter.com/documents/MA/Technical%20Report/2018/NextGen/Appendix%20M%20-%20Plots%20and%20IRT%20Parameters.pdf 

3) Common item numbers/identifiers that relate each question (item) to its parameters: currently missing for MCAS

4) Student responses for each of the test questions, graded as correct/incorrect: we simulate data below

5) A table that converts theta scores to scale scores (and possibly also achievement levels), like table N2, here (shortened): 

![Source: http://www.mcasservicecenter.com/documents/MA/Technical%20Report/2018/NextGen/Appendix%20N%20-%20Scaled%20Score%20Distributions%20and%20Look-up%20Tables_4.17.19.pdf](images/5_theta_to_scale_short.png)
http://www.mcasservicecenter.com/documents/MA/Technical%20Report/2018/NextGen/Appendix%20N%20-%20Scaled%20Score%20Distributions%20and%20Look-up%20Tables_4.17.19.pdf 

# Contents:
### Estimated Scale Scores from Sum Scores:
* Import 3PL IRT item parameters
* Import theta to scale score table
* Simulate student response data
* Estimate student thetas using sum scores
* Convert estimated thetas to scale scores
* Produce table converting sum scores to scale scores, using Test Characteristic Curve information
* Export student ability data, including estimated thetas, scale scores, and achievement levels

### Appendix 1: Simulating Imprecision for Sum Score Theta Estimates
* Invert the Test Characteristic Curve to Produce Estimates of Standard Errors
* Produce table converting sum scores to scale scores, with empirical standard errors, using simulations

### Appendix 2: Scale Score Estimation Using Full-Pattern Scoring
* Estimate student ability using full-pattern scoring, (includes standard errors)
* Export student ability data, including estimated thetas, standard errors, scale scores, and achievement levels

### Appendix 3: Diagnostics
* Report Classical Test Theory statistics
* Plot Item Characteristic Curves and Test Characteristic Curve
* Plot Item Information Functions and Test Information Function

### To do next:
* Format content/hyperlinks within Rmd/html
* Add support for polytomously scored items? (Hand-scored, GRM stuff for MCAS)
* Add support/instructions for 1PL & 2PL models
* Add code to import student responses, including student names/identifiers to attach to the thetas & scale scores


```{r, include = FALSE, message = FALSE}
# Install/update needed packages
#install.packages("irtoys")      # May require some dependencies
#install.packages("readxl")      # Only if importing .xls or .xlsx files, not needed if using .csv files
#install.packages("dplyr")

library(dplyr)
library(readxl)
library(irtoys)
```

# Importing item parameters and scale scores

```{r}
# Import item parameter data
item_parameters_raw <- read_excel("tablem5.xlsx")                            

# Separate the item parameters from the standard errors
my_ip <- as.matrix(item_parameters_raw  %>% dplyr::select(a, b, c))               
my_se <- as.matrix(item_parameters_raw  %>% dplyr::select("se(a)", "se(b)", "se(c)"))

# The MCAS Technical Report tells us they use a normalizing constant of D = 1.701, other states and tests may not have a D at all in their equations
# Set D below, either to 1 if none appears in the 2PL/3PL equations in your technical report, or to the appropriate value (probably 1.7 or 1.701)
D <- 1.701           # Change to D = 1 if none appears in your technical report

# Divide "a" parameters by D, and the se(a) parameters by D^2, to "undo" the normalizing constant that was applied, to fit what the package irtoys expects
my_ip[,1] <- my_ip[,1]/D
my_se[,1] <- my_se[,1]/(D^2)

# Import student responses (if using real data)

# Import theta -> scale score table
scale_scores_raw <- read_excel("tablen2.xlsx")

# Select the relevant columns:
scale_scores <- scale_scores_raw  %>% dplyr::select("Theta", "Scale Score (2018)")

# Plot relationship between thetas and scale scores:
plot(x = scale_scores$Theta, y = scale_scores$`Scale Score (2018)`)

# Relationship is a straight line! Learn the model so we can make this conversion ourselves, later.
theta_to_scale_score <- lm(`Scale Score (2018)` ~ Theta, data = scale_scores)
summary(theta_to_scale_score)
```

# Scale Score Estimation Using Sum Scoring
"Invert" the TCC to get a map from sum scores to thetas:

```{r}
# Plot Test Characteristic Curve (which underlies all of what follows)
# Theta on x axis, predicted sum score on y axis
plot(trf(my_ip))

# Using the smallest and largest thetas provided in the scale_scores table, make a sequence of every possible Theta between these
thetas = seq(from = min(scale_scores$Theta), to = max(scale_scores$Theta), length.out = 100000)
# Calculate the estimated sum score for each of these thetas 
all_sum_scores <- trf(my_ip, x = thetas)

# Simplifies the above possible sum scores (decimals) into possible whole number scores
possible_sum_scores <- seq(from = ceiling(all_sum_scores$f[1]), to = floor(all_sum_scores$f[100000]), by = 1)

# For each possible whole number score, find the associated theta that's the best match
matching_theta_scores <- rep(NA, times = length(possible_sum_scores))
for(i in 1:length(possible_sum_scores)) {matching_theta_scores[i] <- all_sum_scores$x[which.min(abs(all_sum_scores$f - possible_sum_scores[i]))]}

# Produce a table with sum scores, thetas, scale scores, and achievement levels
matching_theta_scores_df <- as.data.frame(cbind(possible_sum_scores, matching_theta_scores))
colnames(matching_theta_scores_df) <- c("SumScore", "Theta")
matching_theta_scores_df$ScaleScore <- predict(theta_to_scale_score, newdata = matching_theta_scores_df)
matching_theta_scores_df$AchievementLevel <- 1
matching_theta_scores_df$AchievementLevel[matching_theta_scores_df$ScaleScore > 470] <- 2
matching_theta_scores_df$AchievementLevel[matching_theta_scores_df$ScaleScore > 500] <- 3
matching_theta_scores_df$AchievementLevel[matching_theta_scores_df$ScaleScore > 530] <- 4
matching_theta_scores_df$ScaleScore <- round(matching_theta_scores_df$ScaleScore)

# View table
matching_theta_scores_df
# Export table
write.csv(matching_theta_scores_df, file = "Estimated_Scale_Scores_From_Sum_Scores.csv", row.names = F)
```

# Appendix 1: Simulating Imprecision for Sum Score Theta Estimates

How do we convey a sense of uncertainty with these sorts of estimates?

Uncertainty arises from two sources:
* students with "fixed" thetas can retake the test and score slightly differently each time
* the standard errors on the item parameter estimates

Simulation 1 focuses only on the retesting, while simulation 2 include both sources of uncertainty. 

## Simulation 1: Theta imprecision from "retesting"

```{r warning=FALSE, message = FALSE}
# Create a sequence of possible thetas, equally spaced
sim_thetas <- seq(from = -4, to = 4, length.out = 801)
# Replicate each of the possible thetas 100 times, as if each of these students took the test 100 times
sim_thetas_n <- rep(sim_thetas, each = 100)
# Simulate the sum scores that these students received, using the item parameters for this test (assume these item parameters are estimated perfectly)
sim_sum_scores <- rowSums(sim(my_ip, sim_thetas_n))
# Combine the thetas and sum scores into a data frame
sim1_long <- as.data.frame(cbind(sim_thetas_n, sim_sum_scores))
# Rename column to the name expected by theta_to_scale_score conversion
colnames(sim1_long) <- c("Theta", "sim_sum_scores")
# Add column for scale scores (from thetas)
sim1_long$sim_scale_scores <- predict(theta_to_scale_score, newdata = sim1_long)

# Group the above data frame by sum scores, and summarise the different thetas that could have produced each sum score
sim1_thetas <- sim1_long %>% 
  group_by(sim_sum_scores) %>% 
  summarise(tibble('2.5' = round(quantile(sim_scale_scores, 0.025), 0),
                   '10' = round(quantile(sim_scale_scores, 0.1), 0),
                   mean = round(mean(sim_scale_scores), 0), 
                   median = round(median(sim_scale_scores), 0), 
                   se = round(sd(sim_scale_scores), 1),
                   '90' = round(quantile(sim_scale_scores, 0.9), 0),
                   '97.5' = round(quantile(sim_scale_scores, 0.975), 0), 
                   max = round(max(sim_scale_scores), 0),
                   nsims = n()))
sim1_thetas

sim1_scale_scores <- sim1_long %>% 
  group_by(sim_sum_scores) %>% 
  summarise(tibble('2.5' = round(quantile(sim_scale_scores, 0.025), 0),
                   '10' = round(quantile(sim_scale_scores, 0.1), 0),
                   mean = round(mean(sim_scale_scores), 0), 
                   median = round(median(sim_scale_scores), 0), 
                   se = round(sd(sim_scale_scores), 1),
                   '90' = round(quantile(sim_scale_scores, 0.9), 0),
                   '97.5' = round(quantile(sim_scale_scores, 0.975), 0), 
                   max = round(max(sim_scale_scores), 0),
                   nsims = n()))
sim1_scale_scores

# Can also create a histogram for the possible thetas that produced each sum score, for example:
hist(sim1_long$Theta[sim1_long$sim_sum_scores == 11], freq = F)
```

## Simulation 2: Theta imprecision arising from both "retesting" and from item parameter imprecision

Simulation 2 takes both sources of error into account to produce a range of possible scale scores for a given sum score
* each simulation will use slightly different item parameters, where each a\*, b\*, and c\* is randomly drawn from ~N(a, se(a)), ~N(b, se(b)), ~N(c, se(c))
* each simulation will use these item parameters to assign probabilities for a simulated "student" of a particular theta getting an item correct, and then "flip a coin" to determine whether that "student" got the item correct
* we then can map fixed student thetas to sum scores, which can then be used backwards to see what range of thetas each sum score could have been produced by

```{r warning=FALSE, message = FALSE}
n_tests = 100
n_students = 100

# Initialise an empty data frame
sim_results <- data.frame(matrix(ncol = 2, nrow = 0))
for(i in 1:n_tests)
{
  new_ip <- cbind(rnorm(n = 15, mean = my_ip[,1], sd = my_se[,1]), 
                rnorm(n = 15, mean = my_ip[,2], sd = my_se[,2]),
                rnorm(n = 15, mean = my_ip[,3], sd = my_se[,3]))
  
  new_thetas <- rnorm(n_students)
  new_responses <- sim(new_ip, new_thetas)
  new_sums <- rowSums(new_responses)
  sim_results <- rbind(sim_results, cbind(new_thetas, new_sums))
}

colnames(sim_results) <- c("Theta", "sim_sum_scores")
sim_results$sim_scale_scores <- predict(theta_to_scale_score, newdata = sim_results)
colnames(sim_results)[1] <- "sim_thetas"

sim2_scale_scores <- as.data.frame(sim_results) %>% 
  group_by(sim_sum_scores) %>% 
  summarise(tibble('2.5' = round(quantile(sim_scale_scores, 0.025), 0),
                   '10' = round(quantile(sim_scale_scores, 0.1), 0),
                   mean = round(mean(sim_scale_scores), 0), 
                   median = round(median(sim_scale_scores), 0), 
                   se = round(sd(sim_scale_scores), 1),
                   '90' = round(quantile(sim_scale_scores, 0.9), 0),
                   '97.5' = round(quantile(sim_scale_scores, 0.975), 0), 
                   max = round(max(sim_scale_scores), 0),
                   nsims = n()))


sim2_scale_scores

# Can even create histograms of likely scale scores given a particular sum score: (eg. 10)
hist(sim_results$sim_scale_scores[sim_results$sim_sum_scores == 10], freq = F)
```

# Appendix 2: Scale Score Estimation Using Full-Pattern Scoring

```{r}
# Use parameter estimates to simulate answers for 100 students
# (Import student data here if using real answers)
set.seed(88)
sim_thetas <- rnorm(100)
sim_responses <- sim(my_ip, sim_thetas)

# Put the parameter estimates and standard errors into the list structure that irtoys functions expect
# Note: ability estimation function does not need standard errors to run
parameter_list <- list(est = my_ip, se = my_se, vcm = NA)

# Estimate student thetas, based on full-pattern scoring, using MLE (several other methods exist in this "ability" function)
mod_MLE<- ability(resp = sim_responses, ip = parameter_list, method = "MLE")

# Look at the first five rows
mod_MLE[1:5, ]

# Convert these estimated thetas to scale scores and achievement levels
ability_df <- as.data.frame(mod_MLE)
colnames(ability_df) <- c("Theta", "se(Theta)", "n")
ability_df$ScaleScore <- predict(theta_to_scale_score, newdata = ability_df)

# Add achievement levels, based on known scale score cutoffs
ability_df$AchievementLevel <- 1
ability_df$AchievementLevel[ability_df$ScaleScore > 470] <- 2
ability_df$AchievementLevel[ability_df$ScaleScore > 500] <- 3
ability_df$AchievementLevel[ability_df$ScaleScore > 530] <- 4

# Round the scale scores to 0 dp before reporting
ability_df$ScaleScore <- round(ability_df$ScaleScore, 0)

# View table:
ability_df

# Export the data 
write.csv(ability_df, file = "Estimated_Scores_From_Full_Pattern_Scores.csv", row.names = F)
# The above file will appear in the file window on the bottom-right hand side of the screen
# To download to local computer, select this file using the checkbox, then use More...Export...
```


# Appendix 3: Diagnostics

## Diagnostics and other test plots:
```{r}
# Simulate data
set.seed(88)
sim_thetas <- rnorm(100)
sim_responses <- sim(my_ip, sim_thetas)

# Classical Test Theory EDA metrics:
# Note: Because the simulated data is pre-graded, we're saying the "answer key" is 1, 1, 1, 1, 1....
ctt <- tia(sim_responses, key = rep(1, 15))

# Show Cronbach's alpha for this "test":
ctt$testlevel$alpha

# Show CTT item-level statistics for first five items
ctt$itemlevel[1:5, ]

# How does the MLE ability estimation perform compared to the "true thetas" from our simulation?
cor(mod_MLE[,1], sim_thetas)
plot(sim_thetas, mod_MLE[,1])

# How do other ability estimation methods perform?
mod_WLE <- ability(resp = sim_responses, ip = parameter_list, method = "WLE")
cor(mod_WLE[,1], sim_thetas)
plot(sim_thetas, mod_WLE[,1])

# Item Characteristic Curves for first five items (this package calls them "item response functions")
plot(irf(my_ip, items = 1:5), co = NA, label = T)

# ICCs for all items:
plot(irf(my_ip), co = NA, label = T)

# Test Characteristic Curve (this package calls this a "test response function")
plot(trf(my_ip))

# Overlaid item information curves
plot(iif(my_ip))

# Test information function
plot(tif(my_ip))

# Cool plot of observed sum scores and predicted sum scores against estimated ability, with +/- 1se bands
scp(sim_responses, my_ip)

# "Empirical response function" for a selected item: observed sum scores vs. percent correct on this question
erf(sim_responses, 1)
```

```{r, include = FALSE}
## Spare parts chunk:

# theta_vec <- seq(from = -4, to = 4, length.out = 101)
# ip = as.data.frame(my_ip)
# 
# # Homemade ICC function: (item number and candidate ability -> candidate probability OR item number -> vector of probabilities)
# my_ICC <- function(item_number, item_params = ip, candidate_ability = NA, min_theta = -4, max_theta = 4, length = 501)
# {
#   theta = candidate_ability
#   if(is.na(candidate_ability))
#     {theta = seq(from = min_theta, to = max_theta, length.out = length)}
#   prob <- item_params$c[item_number] + (1-item_params$c[item_number])/(1+exp(-item_params$a[item_number]*(theta-item_params$b[item_number])))
#   return(prob)
# }
# 
# # Check against package version
# my_ICC(1, length = 101)
# irf(my_ip, items = 1)
# 
# # Homemade TCC function: (candidate theta -> candidate sum score OR no input -> vector of sum scores)
# my_TCC <- function(item_params = ip, candidate_ability = NA, min_theta = -4, max_theta = 4, length = 501)
# {
#   num_items <- nrow(item_params)
#   all_ICCs <- data.frame(matrix(nrow = length, ncol = num_items))
#   for(i in 1:num_items)
#     all_ICCs[,i] <- my_ICC(i, item_params = item_params, candidate_ability = candidate_ability, min_theta = min_theta, max_theta = max_theta, length = length)
#   TCC <- rowSums(all_ICCs)
#   return(TCC)
# }
# 
# # Check against package version
# my_TCC(length = 101)
# trf(my_ip, x = seq(from = -4, to = 4, length.out = 10001))

```